#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>                       //zliu7
#include <opencv2/video/background_segm.hpp>           //zliu7
#include "geometry_msgs/Pose2D.h"
#include <std_msgs/Time.h>
#include <iostream>
#include <stdio.h>
#include <math.h>		//bzj 
#include <stdlib.h>
#include <geometry_msgs/Twist.h>
#include <vector>

using namespace cv;	
using namespace std;
																	//=T
static const std::string OPENCV_WINDOW = "Image window";

//======================================================================================================================================================
//======================================================================================================================================================
geometry_msgs::Pose2D position;				// create a struct to publish cordinate info later on
ros::Publisher pub;
////////////////definition of background substraction//////////////

 Mat fgMaskMOG; //fg mask generated by MOG method
 Ptr <BackgroundSubtractor> pMOG; //MOG Background subtractor

////////////////////////////////////////////////////////////////////
int iLowH_1 = 0;
int iHighH_1 = 69;
int iLowS_1 = 43;
int iHighS_1 = 140;
int iLowV_1 = 126;
int iHighV_1 = 237;


//default capture width and height
const int FRAME_WIDTH = 1288;
const int FRAME_HEIGHT = 964;
//max number of objects to be detected in frame
const int MAX_NUM_OBJECTS=50;
//minimum and maximum object area
const int MIN_OBJECT_AREA = 2*2;
const int MAX_OBJECT_AREA = FRAME_HEIGHT*FRAME_WIDTH/1.5;
//names that will appear at the top of each window
const string windowName = "Original Image";
const string windowName2 = "Thresholded Image 1";

const string windowName_g = "Gaussian Image 1";

const string trackbarWindowName = "Trackbars";

Mat DistortedImg;											//storage for copy of the image raw
Mat	UndistortedImg;											//


double cameraM[3][3] = {{ 521.906925, 0, 330.571743}, {0, 522.912033, 267.759287}, {0, 0, 1}} ;                            
Mat cameraMatrix = Mat(3, 3, CV_64FC1, cameraM);//.inv();

double distortionC[5] = {0.160792,-0.279956,-0.000324,-0.000310, 0};				//distortioncoefficient to be edited
Mat distCoeffs = Mat(1, 5, CV_64FC1, distortionC);							

double rArray[3][3] = {{1, 0, 0}, {0, 1, 0}, {0, 0, 1}};
Mat RArray = Mat(3, 3, CV_64FC1, rArray);					//originally CV_64F

double newCameraM[3][3] = {{532.206543, 0, 330.202770}, {0, 533.930420, 267.077297}, {0, 0, 1}};
Mat NewCameraMatrix = Mat(3, 3, CV_64FC1, newCameraM);
Size UndistortedSize(640, 360);

Mat map1;
Mat map2;												

int xa,ya;
int xa_old, ya_old;
int x_offset=20;               
int y_offset=0;                 


double x_init, z_init, x_final, z_final;
double alpha, beta, angle_dif;

double distance_x, distance_z, rotation_y, asymptote;
int n = 0;
int t= 0;

/**	the following functions are coded by wym, transplanted by bzj
 *  functions include: Get_roi, CircleDetect, insertSort, deletecircle, ColorDetection

/****************** Huo de gan xing qu qu yu ***************

Yuan tu ：Mat&img
Bi cao zuo hou  er zhi hua tu xiang ：Mat&closed
Luan kuo zui xiao chang du：int min_len
Lun kuo zui da chang du ：int max_len
Wai jie ju xing kuan de zui xiao zhi he zui da zhi ：Point width_threshold
Wai jie ju xing gao de zui xiao zhi he zui da zhi ：Point height_threshold
Cun chu gan xing qu qu yu tu kuai ：vector<Mat>&roi_mat
Cun chu gan xing qu qu yu xuan zhuan ju xing：vector<RotatedRect>&roi_Rect

***************** Huo de gan xing qu qu yu ****************/
void Get_roi(Mat&img, Mat&closed,const int min_len, const int max_len, 
	const Point width_threshold,const Point height_threshold,
	const float const_radio,const float e_radio,
	const float min_area, const float max_area,

	vector<Mat>&roi_mat, vector<RotatedRect>&roi_Rect)
{
	vector<vector<Point> > contours;//Cun chu luan kuo 
	//findContours(closed, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_NONE);
	findContours(closed, contours, CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE);
	//cout << "size: " << contours.size() << endl;
	vector<vector<Point> >::iterator it = contours.begin();
	//drawContours(img, contours, -1, Scalar(0, 255, 0), 1);

//	Mat roi, roi2;                   //提取原图像和canny轮廓图像的感兴趣区域
	//float const_radio = 124.0 / 78.0;//固定宽高比
	//float e_radio = 0.5;             //宽高比误差
	while (it != contours.end())
	{
		//cout << it->size() << endl;
		if ((it->size() < min_len) || (it->size() > max_len))//Pai chu chang du guo da he guo xiao de lun kuo
			it = contours.erase(it);
		else
		{
			//cout << it->size() << endl;
			RotatedRect mr = minAreaRect(Mat(*it));
			Rect r0 = mr.boundingRect();
			//	cout << "width: " << r0.width << "  height: " << r0.height << endl;
			float radio = 0.0;

			if ((r0.height > height_threshold.x) && (r0.height<height_threshold.y) && (r0.width>width_threshold.x) && (r0.width<width_threshold.y) &&
				(r0.x>0) && (r0.y>0) && ((r0.x + r0.width)<img.cols) && ((r0.y + r0.height)<img.rows))
			{
				
				radio = ((float)r0.width) / ((float)r0.height);
				if (radio<1.0)radio = 1 / radio;
				//cout << "radio: " << radio << endl;
				if ((radio > const_radio - e_radio) && (radio < const_radio + e_radio))// gen ju zui xiao wai jie ju xing de kuan gao bi jin yi bu pai chu lun kuo gan rao
				{
					float area = (float)r0.width*r0.height;
					if (area > min_area && area < max_area)
					{
						//cout << "area: " << area << endl;
						Mat sub_Mat;
						getRectSubPix(img, Size(r0.width, r0.height), Point2f(r0.x + r0.width / 2.0, r0.y + r0.height / 2.0), sub_Mat);//ti qu ya xiang su jing du de gan xing qu qu yu 
						//rectangle(img, r0, Scalar(0, 0, 255), 2);
						if (sub_Mat.data != NULL)
						{
							roi_mat.push_back(sub_Mat);
							roi_Rect.push_back(mr);
						}

					}
					
				}
				/*rectangle(img, r0, Scalar(0, 0, 255), 2);
				img(r0).copyTo(roi);
				canny(r0).copyTo(roi2);*/
			}

			it++;
		}//end if_else

	}//end while
}

void CircleDetect(Mat&closed, const int min_len, const int max_len, vector<RotatedRect>&Ellp)
{
	vector<vector<Point> > contours;
	findContours(closed, contours, CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE);
	vector<vector<Point> >::iterator it = contours.begin();
	//drawContours(img, contours, -1, Scalar(0, 255, 0), 1);
	while (it != contours.end())
	{
		//cout << it->size() << endl;
		if ((it->size() < min_len) || (it->size() > max_len))
			it = contours.erase(it);
		else
		{
			RotatedRect mr;
			mr = fitEllipse(*it);
		
			if (mr.size.width > 5 && mr.size.width < 50)
			{
				Ellp.push_back(mr);
				
			}
			
			it++;
		}//#end if_else

	}//#end while
}

void insertSort(vector<RotatedRect>&circles,bool f=true)
{
	int n = circles.size();
	RotatedRect temp;
	if (true == f)
	{
		for (int i = 0; i < n; ++i)
		{
			for (int j = i - 1; j >= 0; --j)
			{
				if (circles[j].size.width>circles[j + 1].size.width)
				{
					temp = circles[j + 1];
					circles[j + 1] = circles[j];
					circles[j] = temp;
				}
			}
		}

	}
	else
	{
		for (int i = 0; i < n; ++i)
		{
			for (int j = i - 1; j >= 0; --j)
			{
				if (circles[j].center.x>circles[j + 1].center.x)
				{
					temp = circles[j + 1];
					circles[j + 1] = circles[j];
					circles[j] = temp;
				}
			}
		}

	}
}
void deletecircle(vector<RotatedRect>&circles)
{
	//剔除多余的椭圆
	vector<RotatedRect>::iterator itc = circles.begin() + 1;
	vector<RotatedRect>::iterator itf = circles.begin();

	while (itc != circles.end())
	{
		if (abs(itc->center.x - itf->center.x) < 5 && abs(itc->center.y - itf->center.y) <5)
		{
			itf->center.x = (itf->center.x + itc->center.x) / 2;
			itf->center.y = (itf->center.y + itc->center.y) / 2;
			itf->angle = (itf->angle + itc->angle) / 2;
			itf->size.width = (int)(itf->size.width + itc->size.width) / 2;
			itf->size.height = int(itf->size.height + itc->size.height) / 2;
			itc = circles.erase(itc);
		}
		else
		{
			itf = itc;
			++itc;
		}
	}
}

void ColorDetection(Mat&img,Mat&imgcopy,const int min_h, const int max_h, const bool index)
{

/******************** color detecting **********************/
	
	//cv::imwrite("image_01,jpg",img);

       const float max_sv = 255;
	
	const float minref_sv = 30;
	const float minabs_sv = 80;
	Mat HSV;
	cvtColor(img, HSV, CV_BGR2HSV);

	vector<Mat> hsv;
	split(HSV, hsv);   
	equalizeHist(hsv[2], hsv[2]);
	merge(hsv, HSV);             

	float diff_h = float((max_h - min_h) / 2);
	float avg_h = min_h + diff_h;
	int nl = HSV.rows;
	int nc = HSV.cols*HSV.channels();

	if (HSV.isContinuous())
	{
		nc = nc*nl;
		nl = 1;
	}
	uchar*p;
	int i;
	int j;
	float s_all = 0;
	float v_all = 0;
	float count = 0;

	for (i = 0; i < nl; ++i)
	{
		p = HSV.ptr<uchar>(i);
		
		for (j = 0; j < nc; j += 3)
		{
			int H = int(p[j]);
			int S = int(p[j + 1]);
			int V = int(p[j + 2]);

			s_all += S;
			v_all += V;
			count++;

			bool colormatch = false;

			if (H>min_h && H < max_h)
			{
				float Hdiff = 0;
				if (H > avg_h)
					Hdiff = H - avg_h;
				else
					Hdiff = avg_h - H;
				float Hdiff_p = float(Hdiff / diff_h);

				float min_sv = 0;

				if (true == index)
					min_sv = minref_sv - minref_sv / 2 * (1 - Hdiff_p);  // inref_sv - minref_sv / 2 * (1 - Hdiff_p)
				else
					min_sv = minabs_sv;  // add

				if ((S > min_sv && S<max_sv) && (V>min_sv && V < max_sv))
					colormatch = true;
			}
			if (colormatch == true)
			{
				p[j] = 0;
				p[j + 1] = 0;
				p[j + 2] = 255;

			}
			else
			{
				p[j] = 0;
				p[j + 1] = 0;
				p[j + 2] = 0;
				
			}
		}

	}


	hsv.clear();
	split(HSV, hsv);
	Mat binary;
	binary = hsv[2];

	cv::namedWindow("binary", 0);
	cv::imshow("binary", binary);
	//cv::waitKey(0);
	

/******************** Morphological operations **********************/
	
	

	Mat element(7,7, CV_8U, Scalar(1));
	Mat closed;
	morphologyEx(binary, closed, MORPH_CLOSE, element);
	
	cv::namedWindow("closed", 0);
	cv::imshow("closed", closed);
	//cv::waitKey(0);

	/*Mat thined;
	Thin(closed, thined, 50);*/

	/*cv::namedWindow("thined", 0);
	cv::imshow("thined", thined);
	cv::waitKey(0);*/

	Mat eroded;
	erode(closed, eroded, Mat());

	

	cv::namedWindow("eroded", 0);
	cv::imshow("eroded", eroded);
	//cv::waitKey(0);

	Mat element1(10, 10, CV_8U, Scalar(1));
	Mat dilated;
	dilate(eroded, dilated, element1);

	cv::namedWindow("dilated", 0);
	cv::imshow("dilated", dilated);
	//cv::waitKey(0);

        Mat eroded2;
	erode(dilated, eroded2, Mat());

	cv::namedWindow("eroded2", 0);
	cv::imshow("eroded2", eroded2);

	//clock_t start1, finish1;
	//start1 = clock();

	

	//finish1 = clock();
	//std::cout << "The time1 is: " << (((double)finish1 - start1) / 1000) << " s" << endl;

	
	
	/*Mat element2(13, 13, CV_8U, Scalar(1));
	Mat closed2;
	morphologyEx(thined, closed2, MORPH_CLOSE, element2);
*/
	

	

	/*cv::namedWindow("closed2", 0);
	cv::imshow("closed2", closed2);
	cv::waitKey(0);*/


	//Mat thined2;
	//Thin(dilated, thined2, 50);
	

	//cv::namedWindow("thined2", 0);
	//cv::imshow("thined2", thined2);
	//cv::waitKey(0);
	

/******************** Get interested region **********************/
	

	vector<Mat>roi_mat;
	vector<RotatedRect>roi_Rect;
	const int min_len = 10;
	const int max_len = 800;
	const Point width_threshold = Point(10, 700);
	const Point height_threshold = Point(10, 600);
	const float const_radio = 124.0 / 78.0;//the given width/height
	const float e_radio =2;             //the given the erro of width/height
	Get_roi(img, eroded2, min_len, max_len, width_threshold, height_threshold, const_radio, e_radio, 5000, 200000, roi_mat, roi_Rect);
	if ((roi_mat.size() <= 0) || (roi_Rect.size() <= 0))
	{
		ROS_WARN("There is no region of interest to be recognition!");
		return;
	}
	vector<RotatedRect>::iterator it_Rectf = roi_Rect.begin();
	vector<RotatedRect>::iterator it_Rectc = roi_Rect.begin()+1;
	while (it_Rectc != roi_Rect.end())
	{
		if ((it_Rectf->center.x - it_Rectc->center.x) < 3 && ((it_Rectf->center.y - it_Rectc->center.y) < 3))
		{
			it_Rectf->center.x = (it_Rectf->center.x + it_Rectc->center.x) / 2;
			it_Rectf->center.y = (it_Rectf->center.y + it_Rectc->center.y) / 2;
			it_Rectf->size.width = (it_Rectf->size.width + it_Rectc->size.width) / 2;
			it_Rectf->size.height = (it_Rectf->size.height + it_Rectc->size.height) / 2;
			it_Rectf->angle = (it_Rectf->angle + it_Rectc->angle) / 2;
			it_Rectc = roi_Rect.erase(it_Rectc);
		}
		else
		{
			it_Rectf = it_Rectc;
			it_Rectc++;
		}
	}
	

	int n = roi_Rect.size();
///	std::cout << "n: " << n << endl;
	if (n <= 0)
	{
		ROS_WARN("all region of interest is missing!");
		return;
	}

	for (int i = 0; i < n; ++i)
	{
		Point2f vertices[4];
		roi_Rect[i].points(vertices);
		circle(imgcopy, vertices[0], 5, Scalar(255, 0, 0), 1);
		line(imgcopy, vertices[0], vertices[1], Scalar(255, 0, 0), 1);
		line(imgcopy, vertices[1], vertices[2], Scalar(0, 255, 0), 1);
		line(imgcopy, vertices[2], vertices[3], Scalar(0, 0, 255), 1);
		line(imgcopy, vertices[3], vertices[0], Scalar(255, 0, 255), 1);
	}
	
	

/******************** Ellipse detecting **********************/

	

	GaussianBlur(img, img, Size(5, 5), 0, 0, BORDER_DEFAULT);
	Mat canny;
	Canny(img, canny, 50, 130);

	Mat element3(3, 3, CV_8U, Scalar(1));
	Mat closed3;
	morphologyEx(canny, closed3, MORPH_CLOSE, element3);
	
	cv::namedWindow("canny", 0);
	cv::imshow("canny", canny);
	//cv::waitKey(0);

	

	vector<RotatedRect> Ellp;
	CircleDetect(closed3, 10, 100, Ellp);

	
	insertSort(Ellp);
	deletecircle(Ellp);
	insertSort(Ellp,false);

	

	vector<RotatedRect>::iterator it_Ellp = Ellp.begin();
	vector<RotatedRect> ellp;
	//RotatedRect ellp[3];
	int ii = 0;
	//int a = 5;
	int num = 0;
	while (it_Ellp != Ellp.end())
	{
		if (it_Ellp->size.width < 10 || it_Ellp->size.width> 80 || it_Ellp->size.height < 10 || it_Ellp->size.height >80)
			it_Ellp = Ellp.erase(it_Ellp);
		else
		{
			while (ii < n)
			{
				Point2f vertices[4];
				roi_Rect[ii].points(vertices);
				double a1, a2, a3, a4;
				double b1, b2, b3, b4;
				a1 = (vertices[0].y - vertices[1].y) / (vertices[0].x - vertices[1].x);
				a2 = (vertices[1].y - vertices[2].y) / (vertices[1].x - vertices[2].x);
				a3 = (vertices[2].y - vertices[3].y) / (vertices[2].x - vertices[3].x);
				a4 = (vertices[3].y - vertices[0].y) / (vertices[3].x - vertices[0].x);

				b1 = vertices[0].y - a1*vertices[0].x;
				b2 = vertices[1].y - a2*vertices[1].x;
				b3 = vertices[2].y - a3*vertices[2].x;
				b4 = vertices[3].y - a4*vertices[3].x;

				int x = it_Ellp->center.x;
				int y = it_Ellp->center.y;
				bool flag1 = false;
				bool flag2 = false;
				double y1, y2, y3, y4;
				y1 = a1*x + b1;
				y2 = a3*x + b3;
				double ee = 10;
				if ((y > y1 + ee&&y < y2 - ee) || (y>y2 + ee&&y<y1 - ee))
					flag1 = true;
				y3 = a2*x + b2;
				y4 = a4*x + b4;
				if ((y>y3 + ee&&y<y4 - ee) || (y>y4 + ee&&y<y3 - ee))
					flag2 = true;

				if (flag1&&flag2)
				{
					//ellipse(imgcopy, *it_Ellp, Scalar(0, 255, 0), 1);
				   /*std::cout << Point(x, y) << endl;
				   std::cout << it_Ellp->size.width << "\t" << it_Ellp->size.height << endl;
					cv::namedWindow("imgcopy", 0);
					cv::imshow("imgcopy", imgcopy);
					cv::waitKey(0);
					a+=10;*/
					//ellp[num] = *it_Ellp;
					ellp.push_back(*it_Ellp);
					num++;
				}

				ii++;
			}
			ii = 0;
			it_Ellp++;
		}
	}

	if (ellp.size() <= 1)
	{
		ROS_WARN("There is only one elllipse!");
		return;
	}
	vector<RotatedRect>::iterator it_ellpc = ellp.begin() + 1;
	vector<RotatedRect>::iterator it_ellp  = ellp.begin();
	while (it_ellpc != ellp.end())
	{
		if (abs(it_ellp->center.x - it_ellpc->center.x) < 3 && abs(it_ellp->center.y - it_ellpc->center.y)<3)
			it_ellpc = ellp.erase(it_ellpc);
		else
		{
			ellipse(imgcopy, *it_ellp, Scalar(0, 255, 0), 1);
			it_ellp = it_ellpc;
			it_ellpc++;
		}
	}
	ellipse(imgcopy, *it_ellp, Scalar(0, 255, 0), 1);


	/*double x1 = (ellp[0].size.width*ellp[0].size.height) / (ellp[2].size.width*ellp[2].size.height);
	double x2 = (ellp[2].size.width*ellp[2].size.height) / (ellp[1].size.width*ellp[1].size.height);
	double x3 = (ellp[1].size.width*ellp[1].size.height) / (ellp[0].size.width*ellp[0].size.height);
	cout << "x1: " << x1 << " x2: " << x2 << " x3: " << x3 << endl;
	cout << "area 0: " << ellp[0].size.width*ellp[0].size.height << endl;
	cout << "area 1: " << ellp[1].size.width*ellp[1].size.height << endl;
	cout << "area 2: " << ellp[2].size.width*ellp[2].size.height << endl;*/
//	std::cout << "num: " << num << endl;
	
}//end of ColorDetection

void createTrackbars(){
	//create window for trackbars

    namedWindow("Control_1", CV_WINDOW_AUTOSIZE);
	//create memory to store trackbar name on window
	//create trackbars and insert them into window
	//3 parameters are: the address of the variable that is changing when the trackbar is moved(eg.H_LOW),
	//the max value the trackbar can move (eg. H_HIGH), 
	//and the function that is called whenever the trackbar is moved(eg. on_trackbar)
	//                                  ---->    ---->     ---->      
 //Create trackbars in "Control" window
	cvCreateTrackbar("LowH_1", "Control_1", &iLowH_1, 179); //Hue (0 - 179)
	cvCreateTrackbar("HighH_1", "Control_1", &iHighH_1, 179);

	cvCreateTrackbar("LowS_1", "Control_1", &iLowS_1, 255); //Saturation (0 - 255)
	cvCreateTrackbar("HighS_1", "Control_1", &iHighS_1, 255);

	cvCreateTrackbar("LowV_1", "Control_1", &iLowV_1, 255); //Value (0 - 255)
	cvCreateTrackbar("HighV_1", "Control_1", &iHighV_1, 255);
	
}

string intToString(int number){
	std::stringstream ss;
	ss << number;
	return ss.str();
}

void drawObject(int x, int y,Mat &frame){  //RED TARGET

	//use some of the openCV drawing functions to draw crosshairs
	//on the tracked image!

	circle(frame,Point(x,y),20,Scalar(0,255,0),2);

    if(y-25>0)
    line(frame,Point(x,y),Point(x,y-25),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(x,0),Scalar(0,255,0),2);
    if(y+25<FRAME_HEIGHT)
    line(frame,Point(x,y),Point(x,y+25),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(x,FRAME_HEIGHT),Scalar(0,255,0),2);
    if(x-25>0)
    line(frame,Point(x,y),Point(x-25,y),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(0,y),Scalar(0,255,0),2);
    if(x+25<FRAME_WIDTH)
    line(frame,Point(x,y),Point(x+25,y),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(FRAME_WIDTH,y),Scalar(0,255,0),2);

	putText(frame,intToString(x)+","+intToString(y),Point(x,y+30),1,1,Scalar(0,255,0),2);

}

void morphOps(Mat &thresh){
	//create structuring element that will be used to "dilate" and "erode" image.
    //dilate with larger element so make sure object is nicely visible

	erode(thresh,thresh,getStructuringElement( MORPH_RECT,Size(2,2)));
	dilate(thresh,thresh,getStructuringElement( MORPH_RECT,Size(2,2)));	
}

void trackFilteredObject1(int &x, int &y, Mat threshold, Mat &cameraFeed, int &x_offset, int &y_offset){

	Mat temp;
	threshold.copyTo(temp);				//these two vectors needed for output of findContours
	vector< vector<Point> > contours;
	vector<Vec4i> hierarchy;			//find contours of filtered image using openCV findContours function
	findContours(temp,contours,hierarchy,CV_RETR_EXTERNAL,CV_CHAIN_APPROX_SIMPLE );
	double refArea = 0;
	bool objectFound = false;

	if (hierarchy.size() > 0) 			//if number of objects greater than MAX_NUM_OBJECTS we have a noisy filter
	{
		int numObjects = hierarchy.size();
		
        if(numObjects<MAX_NUM_OBJECTS)
        {
			for (int index = 0; index >= 0; index = hierarchy[index][0]) 
			{
				Moments moment = moments((cv::Mat)contours[index]);	//use moments method to find our filtered object
				double area = moment.m00;

				//if the area is less than 20 px by 20px then it is probably just noise
				//if the area is the same as the 3/2 of the image size, probably just a bad filter
				//we only want the object with the largest area so we safe a reference area each
				//iteration and compare it to the area in the next iteration.
                //if(area>MIN_OBJECT_AREA && area<MAX_OBJECT_AREA && area>refArea)
                if(area>MIN_OBJECT_AREA && area>refArea)
                {
					x = moment.m10/area;
					y = moment.m01/area;
					//objectFound = true;
					
					refArea = area;
					
					if (n == 0)
					{
					xa_old = x;
					ya_old = y;
					n = 1;
					}
					
					if ((abs(xa_old-x)<= 2) && (abs(ya_old-y) <= 2))
					{
						xa = xa_old;
						ya = ya_old;
					}
					else 
					{	
                    xa = x+x_offset;
                    ya = y+y_offset;
                    xa_old = x+x_offset;
                    ya_old = y+y_offset;
                    
                    }
				}
				//else if( area  refArea )objectFound = false;

			}
			//let user know you found an object
			//if(objectFound == true)
			//{
			putText(cameraFeed,"Tracking Object",Point(0,50),2,1,Scalar(0,255,0),2);
				//draw object location on screen
				drawObject(xa,ya,cameraFeed);

		}else putText(cameraFeed,"TOO MUCH NOISE! ADJUST FILTER",Point(0,50),1,2,Scalar(0,0,255),2);
	}
}


void imageCb(const sensor_msgs::ImageConstPtr& msg){  
    cv_bridge::CvImagePtr cv_ptr;													   
    try
    {
      cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);   			//convert ROS image to CV image and make copy of it storing in cv_ptr(a pointer)
    }
    catch (cv_bridge::Exception& e)
    {
      ROS_ERROR("cv_bridge exception: %s", e.what());
      return;
    }
    imwrite("box_color_test.jpg",cv_ptr->image);
	/*	image working procedure starting from here inside the main function.
	 *  The purpose of the image processing is to use the existing video to working out the 
	 *  cordinate of the detected object, using color extraction technique.
	 */
    bool trackObjects = true;
    bool useMorphOps = true;

	Mat cameraFeed;

	Mat HSV_1;
    
	Mat threshold_1;
	//x and y values for the location of the object
	int x=0, y=0;
	createTrackbars();

		//store image to matrix
		cv_ptr->image.copyTo(DistortedImg);											//=Tan= copy the image from ardrone to DistortedImg for processing
		initUndistortRectifyMap(cameraMatrix, distCoeffs, RArray, NewCameraMatrix, UndistortedSize, CV_32FC1, map1, map2);
		remap(DistortedImg, cameraFeed, map1, map2, INTER_LINEAR, BORDER_CONSTANT, Scalar(0,0,0));		// maybe try this one instead of the above two instead: cv::undistort(image, undistorted, cameraMatrix, distCoeffs);
//////////////////////////////////////////background substraction 1////////////////////////////////////////////////////////////////
    
	/**
	 *	the following coded by wym, transplanted by bzj,
	 *	the transplanted section ended by the comment of "end of transplant"
	 */	
	
	Mat imgcopy;
	cameraFeed.copyTo(imgcopy);
	ColorDetection(cameraFeed, imgcopy,130, 310, false);
	cv::namedWindow("imgcopy1", 0);
	cv::imshow("imgcopy1", imgcopy);
	
    //end of transplant

  pMOG->operator()(cameraFeed, fgMaskMOG);
  imwrite( "fgMaskMOG.jpg", fgMaskMOG);
////////////////////////////////////////HSV/////////////////////////////////////////////////////////////////////////////////////
		//convert frame from BGR to HSV colorspace
		cvtColor(cameraFeed,HSV_1,COLOR_BGR2HSV);

		//fiter HSV image between values and store filtered image to
		//threshold matrix
				
		//output the after-threshold matrix to Mat threshold
		inRange(HSV_1,Scalar(iLowH_1, iLowS_1, iLowV_1),Scalar(iHighH_1, iHighS_1, iHighV_1),threshold_1); 
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
               Mat fgMaskMOG_ROI(fgMaskMOG,Rect(20, 0, 610, 190));
		//perform morphological operations on thresholded image to eliminate noise
		//and emphasize the filtered object(s)
		if(useMorphOps)
		{
			//morphOps(threshold_1);
                        //morphOps(fgMaskMOG);
                        morphOps(fgMaskMOG_ROI);
		}
		//pass in thresholded frame to our object tracking function
		//this function will return the x and y coordinates of the
		//filtered object
		if(trackObjects)
		{
		//	trackFilteredObject1(x,y,threshold_1,cameraFeed);
                //        trackFilteredObject1(x,y,fgMaskMOG,cameraFeed);
                        trackFilteredObject1(x,y,fgMaskMOG_ROI,cameraFeed,x_offset,y_offset);
		}


//		imshow(windowName2,threshold_1);
		imshow(windowName,cameraFeed);		
                imshow(windowName_g,fgMaskMOG);
               imwrite("table.jpg", cameraFeed);
//		imshow("HSV",HSV_1);
  cv::waitKey(30);  //to show video steady.
////////////////////////////////////publish object information to path planner///////////////////////////////////////////////
  ros::NodeHandle nh;
  geometry_msgs::Twist cv_p;
  cv_p.linear.x=xa;
  cv_p.linear.y=ya;
  cv_p.linear.z=0;
  cv_p.angular.x=0;
  cv_p.angular.y=0;
  cv_p.angular.z=0;
  ros::Publisher cv_p_pub = nh.advertise<geometry_msgs::Twist>("cv_position",1);
  ROS_INFO("target.x312 is %.2f, target.y is %.2f)",cv_p.linear.x,cv_p.linear.y);
  std_msgs::Time time;
  time.data=ros::Time::now();
  while(ros::Time::now() - time.data < ros::Duration(0.05))
  {
    cv_p_pub.publish(cv_p);
  }
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
  
  }

int main(int argc, char** argv){
  ros::init(argc, argv, "object_detect");
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_(nh_);
  image_transport::Subscriber image_sub_;
  
  pMOG = new BackgroundSubtractorMOG();
  ros::Rate loop_rate(100);
  image_sub_ = it_.subscribe("/camera/rgb/image_raw", 1, imageCb); 			                                    

  ros::spinOnce();
  int count = 0;
  while (ros::ok())
  {
    ros::spinOnce();
    loop_rate.sleep();

    ++count;
  }
  return 0;
}
